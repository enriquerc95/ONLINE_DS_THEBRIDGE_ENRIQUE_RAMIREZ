{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e33cd0-254d-4171-a12a-f5f77ac73812",
   "metadata": {},
   "source": [
    "## Acceso Local: Lectura, Escritura y ficheros TXT\n",
    " Un archivo es un conjunto de datos almacenados en el ordenador en forma de bits.\n",
    "Header: metadatos del archivo (nombre, tamaño, tipo...)\n",
    "Data: contenido del archivo\n",
    "End of file (EOF): caracter especial que indica el final del archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8ae53-1e4b-4ec1-b6a4-00213da4f8b5",
   "metadata": {},
   "source": [
    "Si estamos trabajando en el directorio to, accederemos a cats.gif como cats.gif\n",
    "Si queremos leer dog_breeds.txt, hay que ir un directorio hacia atrás, ../dog_breeds.txt\n",
    "Y si queremos acceder a animals.csv, son dos directorios hacia atrás: ../../animals.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db209ab-2d59-4b3a-a10e-73b96a5439e9",
   "metadata": {},
   "source": [
    "## 2. Abrir ficheros\n",
    " **usaremos la función `open`**, que devuelve un objeto de tipo `File`, con unos métodos y atributos propios empleados para obtener información de los archivos abiertos. `open` sigue la siguiente sitaxis:\n",
    "\n",
    "```Python\n",
    "file_object  = open(\"filename\", \"mode\")\n",
    "```\n",
    "el modo nos dice si leemos en modo lectura o escrtura.\n",
    "l primer argumento es el nombre del archivo, mientras que en el modo tendremos que especificar si queremos leer, o escribir. Por defecto leerá, es decir, el parámetro valdrá *r*, de read. [Te dejo el enlace a la documentación para consultar el resto de modos](https://docs.python.org/3/library/functions.html#open).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc235ca-c579-4aaf-8fd0-3893cc44ba57",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/dog_breeds.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#leer ficheros de texto\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/dog_breeds.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m open_file: \u001b[38;5;66;03m#r no haría falta, porque viene por defecto\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     all_text \u001b[38;5;241m=\u001b[39m open_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(all_text))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/dog_breeds.txt'"
     ]
    }
   ],
   "source": [
    "#leer ficheros de texto\n",
    "with open(\"./data/dog_breeds.txt\", \"r\") as open_file: #r no haría falta, porque viene por defecto\n",
    "    all_text = open_file.read()\n",
    "    print(type(all_text))\n",
    "    print(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369970ff-3653-4b0c-8f15-1baa4c3bb189",
   "metadata": {},
   "source": [
    "El método `.read()` nos devuelve un string con todo el texto, que no es lo ideal para tratar luego los datos.\n",
    "\n",
    "En el siguiente ejemplo vemos como también lo leemos, pero en este caso cada línea la guarda en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae5fed1-2e4c-4e5c-aff6-7d8ab418549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dog_breeds.txt\", \"r\") as open_file:\n",
    "    all_text = open_file.readlines()\n",
    "    print(type(all_text))\n",
    "    print(all_text) #le añade el salto de carro \"\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d9f16-f987-4f98-985e-45dd2d2d374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#otro estilo\n",
    "with open(\"./data/dog_breeds.txt\", \"r\") as f:\n",
    "   lineas = [line.replace(\"\\n\",\"\") for line in f] #lee linea a linea f y la devuelvbe a variable line\n",
    "#crea otra lista por compresion, quita el retorno de carro y devuelve \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211da5fe-63d6-4804-b759-8482d49860a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compresión\n",
    "#quitar terrier y spanyel de las lineas\n",
    "nuevos_datos = [perrito.replace(\"Terrier\",\"\").replace(\"Spaniel\",\"\") for perrito in lineas]\n",
    "nuevos_datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099def3-35d4-476c-8918-5d3845138dbc",
   "metadata": {},
   "source": [
    "Y ahora para escribir sólo tenemos que cambiar el modo a \"w\" (sobreescribiremos lo que haya) o \"a\" (añadiremos al final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c4661-48a5-4f7c-b460-7f33699cd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/dog_breeds.txt\", \"w\") as g: #suele escribir f y g\n",
    "    for linea in nuevos_datos:\n",
    "        g.write(linea + \"\\n\")\n",
    "with open(\"./data/dog_breeds.txt\", \"r\") as f: #para comprobarlo lo abrimos\n",
    "    for linea in f:\n",
    "        print(linea) #nos da el salto de carro del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d82e42-82c1-41d9-945c-cc96eeb23c1c",
   "metadata": {},
   "source": [
    "## ACCESO LOCAL: Ficheros .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c6be4-07dd-453f-b9b9-d56fa13edc0e",
   "metadata": {},
   "source": [
    "**Los ficheros csv (*Comma Separated Values*) son el estándar de la industria que se utiliza para leer/escribir datos en formato tabla**\n",
    "todos los valores de las columnas van separados por comas, y las filas por saltos de línea. **Su extension de archivo es `.csv`**\n",
    "**Es el archivo más común utilizado para guardar datos tabulares, puesto que ocupa muy poco espacio**\n",
    "No usar la , como separador, ya que podemos confundir a pandas, ya que aquí la coma indica que es el sistema decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdc1f7-7712-4c98-8063-2954cd60236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leamos uno de los ficheros csv que hemos visto en sesiones anteriores\n",
    "with open(\"./data/df_liga_2019.csv\",\"r\", encoding = \"utf8\") as f: #cuando falle alguna lectura de texto, añadir encoding utf8 no latin1\n",
    "   datos = [linea.replace(\"\\n\",\"\") for linea in f]\n",
    "\n",
    "# Veamos las primeras 10 filas\n",
    "datos[0:10]\n",
    "#nos da linea a linea el fichero csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035838c1-007b-419d-b5f5-95394b079b7b",
   "metadata": {},
   "source": [
    "### Pandas y csv: Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d032e74-8fa6-40f1-b936-5c724541855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/df_liga_2019.csv\")\n",
    "df.head() #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a3594-4f08-4f57-8fa3-bbd5dc411d2c",
   "metadata": {},
   "source": [
    "Vamos a ver algunos **parámetros interesantes del `read_csv()`**\n",
    "1. `index_col`: indica cual de las columnas queremos que sea el índice (necesitamos que tenga cabecera claro, ver más abajo)\n",
    "2. `names`: sirve para indicar el nombre de las columnas, por si no queremos el que venga en el fichero (ojo, es posicional, la primera columna se llamará como el primer elemento del argumento names, y así sucesivamente)\n",
    "2. `sep`: el separador de los datos, por defecto es coma, pero podría ser otro como veremos en ejemplos posteriores.\n",
    "3. `header`: dónde se encuentran los nombre de columnas. Por defecto es en la primera línea. [En general se usa para indicar que no viene con cabecera, entonces tendremos que usar names para dar el nombre de las columnas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380286fd-7c7c-4fd4-9553-5742c05ce859",
   "metadata": {},
   "source": [
    "#### index_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05a55f-e14d-44a2-9253-f97df43867fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/df_liga_2019.csv\", index_col = \"id_partido\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166558b5-3026-426c-badd-3382bd74170c",
   "metadata": {},
   "source": [
    "#### names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a65d40-d981-41e0-b4e5-113c0a6369a1",
   "metadata": {},
   "source": [
    "#traducir al ingles\n",
    "\n",
    "df.columns\n",
    "\n",
    "Index(['equipo_local', 'equipo_visitante', 'Division', 'Temporada', 'fecha_dt',\n",
    "       'goles_local', 'goles_visitante', 'arbitro', 'estadio', 'odd_1',\n",
    "       'odd_x', 'odd_2', 'Informe_Tarjetas', 'Asistencia_miles'],\n",
    "      dtype='object')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e9e12-5e9f-4f66-bb3d-78d81040a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/df_liga_2019.csv\",\n",
    "                 names = [\"id_fixture\",\"home_team\",\"away_team\",\"division\",\"season\",\"date_dt\",\n",
    "                          \"goals_home\",\"goals_away\",\"referee\",\"stadium\",\"odd_1\",\"odd_draw\",\"odd_2\",\n",
    "                          \"Card_report\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31aab82-42fa-4688-99ab-0cbe2b5ddea9",
   "metadata": {},
   "source": [
    "#### sep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb366b-f879-4e53-8aaf-87f6061f4cd8",
   "metadata": {},
   "source": [
    "El argumento `sep` nos permite leer un archivo CSV que no esté separado por comas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b52a51-dbe9-4ded-acbd-0df3a21957ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/df_liga_2019_pipe.csv\")\n",
    "df #si no tiene comas, lo interpreta que todo va junto.\n",
    "# lo ha convertido en una sola columna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5da69-e6c3-4ac1-a270-8f851eca2af9",
   "metadata": {},
   "source": [
    "id_partido|equipo_local|equipo_visitante|Division|Temporada|fecha_dt|goles_local|goles_visitante|arbitro|estadio|odd_1|odd_x|odd_2|Informe_Tarjetas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca284b-9a82-4ea3-ba3c-51f93b36567b",
   "metadata": {},
   "source": [
    "Lo lee todo como una única línea ya que no encuentra comas. **Se recomienda trajar con CSVs cuyo separador sea el \";\" o el \"|\" así evitamos problemas por los decimales**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2829eb6-5670-4bb8-a22d-ab43ff0ebe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/df_liga_2019_pipe.csv\", sep = \"|\", index_col = \"id_partido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4093d-b275-4d1a-85ed-a4ad964b3917",
   "metadata": {},
   "source": [
    "### Pandas y csv: Escritura\n",
    "Para escribir un CSV usamos el método `to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85484355-c4ea-4461-a59d-e35ad3bfc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/df_ejemplo_write.csv\", sep = \"|\", index = False) #sep iondica el separador e index indica si queremosd el índice o no\n",
    "#el indice está a true, por lo que si es false debe eliminarlo\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ece776-f809-484d-9809-961bb58052cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/df_ejemplo_write.csv\", \"r\", encoding = \"utf8\") as f:\n",
    "    datos = [linea.replace(\"\\n\",\"\") for linea in f]\n",
    "datos[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f0400-e4f0-429c-ab75-ab1bd44b4510",
   "metadata": {},
   "source": [
    "## ACCESO LOCAL: Ficheros Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6bdcc-38e7-40fe-86aa-e124a4db1c73",
   "metadata": {},
   "source": [
    " Las extensiones de archivo más habituales son `.xslx` y `.xls`. Por suerte, **`pandas` tiene una función para leer los formatos de archivo de Excel y un método para escribirlos**.\n",
    " El método para leer archivos excel tiene una lógica simiar al `read_csv` pero se llama `read_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3bfc1-c0a9-400b-b765-d07f2e646ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"./data/df_liga_2019.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e8cec2-078e-403c-b5ab-5bdcf2ea238a",
   "metadata": {},
   "source": [
    "#### ARGUMENTOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a0085-9bc2-4ce6-96db-354c63ca0036",
   "metadata": {},
   "source": [
    "### sheet_name\n",
    "ste argumento permite indicar las hojas queremos leer usando su nombre o posición en el \"libro\". Si no se pone nada lee la primera según esté ordenado el fichero excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf9564-45b2-4d51-b94b-2cedb19e0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./data/df_liga_2019.xlsx\", sheet_name = \"futbol_2\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c438e6-2878-498e-a2ef-47714599a754",
   "metadata": {},
   "source": [
    "Se puede leer la hoja por posición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5714b62-c44c-48b8-9cce-08851d07ae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se puede leer la hoja por posición\n",
    "df = pd.read_excel(\"./data/df_liga_2019.xlsx\", sheet_name = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb371e4-43bd-486b-87e4-e48e34c0a193",
   "metadata": {},
   "source": [
    "Puedes indicarle una lista con las posiciones o los nombres de varias hojas, e incluso `None` si quieres cargar todas. En estos casos la función devuelve un diccionario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba31be4-05ac-4f17-892b-bffa1be75a59",
   "metadata": {},
   "source": [
    "#### index_col\n",
    "Tiene el mismo uso que en read_csv, sirve para indicar la columna que funciona de índice. Si se leen varias hojas a la vez se puede pasar a index col una lista con los nombres de las columnas que se usenm con índice para cada unade las posiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c379b5ed-5352-43f1-b9e7-77325cdec3c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/df_liga_2019.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid_partido\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"./data/df_liga_2019.xlsx\", index_col = \"id_partido\")\n",
    "df #id_partido lña convierte en el índice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea725e1-bb99-4759-9172-410bf693caac",
   "metadata": {},
   "source": [
    "#### usecols y skiprows\n",
    "Si los datos no empiezan en la columna A y en la fila 1, leeremos mal estos si hacemos uso de la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c998272-6c95-4f52-bbc9-a56a176b284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./data/df_liga_2019.xlsx\", sheet_name = \"futbol_3\")\n",
    "df #coge mal las columnas, y tiene muchos nan, empieza en la fila 3 (C)y los datos empiezan en la columna 3  y en la 4 columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b279e15-959b-4cea-b10f-6c2a7d1c7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./data/df_liga_2019.xlsx\", sheet_name = \"futbol_3\", usecols =\"C:N\", skiprows = [0,1,2,8,14])\n",
    "df #eliminamos las columnas y filkas que no tienen datos, no hya filas  con nan y las columnas están en su sitio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0196ac-e014-42dd-9eaf-73fcc05fef3b",
   "metadata": {},
   "source": [
    "### Pandas y excel: Escritura\n",
    "Al igual que con el CSV, tenemos el método `to_excel()`, para escribir el `DataFame` en un archivo Excel.  \n",
    "no usaremos el parámetro sep, pero sí el index\n",
    " con las mismas consideraciones que para `read_csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90aa5199-36df-4a3f-b719-6a0293406079",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/df_ejemplo_excel.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, sheet_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/df_ejemplo_excel.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_2\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_excel(\"./data/df_ejemplo_excel.xlsx\", sheet_name = \"Test\")\n",
    "df_2 = pd.read_excel(\"./data/df_ejemplo_excel.xlsx\")\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630443de-9f7a-491e-91ff-a88b5015b681",
   "metadata": {},
   "source": [
    "## ACCESO LOCAL: JSON (I)\n",
    "**Los fichero Json, o *JavaScript Objet Notation* es otro formato de texto plano que se utiliza para el itercambio de datos**.\n",
    "formato de datos independiente del lenguaje. JavaScript es un lenguaje de programación web, por lo que JSON se utiliza mucho en el intercambio de objetos entre cliente y servidor.\n",
    "no iene esa estructura de fila/columna, sino que ahora es un formato tipo clave/valor, como si fuese un diccionario.\n",
    "Es un  fichero para guardar diccionarios o lista de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3c682-16c7-4e89-842c-4102cc933334",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diccionario único\n",
    "with open(\"./data/single_json.json\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e824b4-cdf3-41fa-a64b-6d56e2d22d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una lista de diccionarios\n",
    "with open(\"./data/presidentes_short.json\", \"r\") as f:\n",
    "    for linea in f:\n",
    "        print(linea, end =\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13979e-6f7f-47e4-90ae-44514adf4f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un diccionario por línea\n",
    "with open(\"./data/Musical_short.json\",\"r\") as f:\n",
    "    for linea in f:\n",
    "        print(linea, end =\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba62b0-ed0c-42c3-82a4-609e9b632534",
   "metadata": {},
   "source": [
    "### Lectura y extracción de datos de archivos Json\n",
    "Se puede leer el fichero como un texto plano con open, pero los datos lo leeremos a través de la librería jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08132f3b-9548-4aed-b2cf-f20be95088ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1a04a-f300-41a1-8efd-9c84a0a4d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/single_json.json\",\"r\") as f: # Esto igual que para leer texto\n",
    "    datos = json.load(f) # esto es lo que cambia\n",
    "print(type(datos))\n",
    "datos #después de haberlo importado, podemos recorrerlo y editarlo como un diccionario normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd8469-1299-4e24-ba45-c86c9b95bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/presidentes_short.json\",\"r\") as f:\n",
    "    datos = json.load(f)\n",
    "print(type(datos))\n",
    "datos #esto da la lista de diccionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b275be-f854-423a-9dba-94f0119dfc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/Musical_short.json\",\"r\") as f:\n",
    "    datos  = json.load(f)\n",
    "print(type(datos))\n",
    "datos #este nos da error, ya que está pensado para leerlo con pandas y json no puede leerlo normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361f9bd-575f-4d77-814f-1ffc71050358",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/Musical_short.json\",\"r\") as f:\n",
    "    datos = [json.loads(linea) for linea in f] # Fijate que tiene una \"s\", porque aquí no estamos leyendo de un archivo sino de un string\n",
    "print(type(datos))\n",
    "datos\n",
    "#en vez de aplicar el json load a todo el descriptor, lo leemos linea a linea y usamos el json loads y le pasamos un string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6de07c-ba11-4de5-9921-fc1fe19677f3",
   "metadata": {},
   "source": [
    "clicka la celda para verlo\n",
    "<class 'list'>\n",
    "[{'reviewerID': 'A2IBPI20UZIR0U',\n",
    "  'asin': '1384719342',\n",
    "  'reviewerName': 'cassandra tu \"Yeah, well, that\\'s just like, u...',\n",
    "  'helpful': [0, 0],\n",
    "  'reviewText': \"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\",\n",
    "  'overall': 5.0,\n",
    "  'summary': 'good',\n",
    "  'unixReviewTime': 1393545600,\n",
    "  'reviewTime': '02 28, 2014'},\n",
    " {'reviewerID': 'A14VAT5EAX3D9S',\n",
    "  'asin': '1384719342',\n",
    "  'reviewerName': 'Jake',\n",
    "  'helpful': [13, 14\n",
    "  'reviewText': \"The product does exactly as it should and is quite affordable.I did not realized it was double screened until it arrived, so it was even better than I had expected.As an added bonus, one of the screens carries a small hint of the smell of an old grape candy I used to buy, so for reminiscent's sake, I cannot stop putting the pop filter next to my nose and smelling it after recording. :DIf you needed a pop filter, this will work just as well as the expensive ones, and it may even come with a pleasing aroma like mine did!Buy this product! :]\"\n",
    "\n",
    "  \n",
    "'en datos tengo una lista y cada elemento es el diccionario que correesponde a cada fila'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6b97c-534b-4650-8af5-2179909c48c5",
   "metadata": {},
   "source": [
    "### Escritura en archivos json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee48fb-ea2f-41ea-9a10-be1e4a9aa496",
   "metadata": {},
   "outputs": [],
   "source": [
    " lo que vayas a escribir debe cumplir con la especificación de lo que es un objeto Json\n",
    "no se pueden escribir imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707cc55b-a5e4-4fad-b0a5-b56201fad603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_ejemplo = {\"nombre\": \"Motomami\",\"cantante\":\"Rosalia\", \"anyo\": \"2021\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402c747-6db6-4c69-9d0f-cd73ae9512ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar ejemplo\n",
    "with open(\"./data/ejemplo.json\",\"w\") as g:\n",
    "    json.dump(dicc_ejemplo, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324bb53b-24e6-4c83-a282-509d69a1c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/ejemplo.json\",\"r\") as f:\n",
    "    datos_ejemplo = json.load(f)\n",
    "\n",
    "datos_ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874cdb94-040c-4679-8be5-30c2c481c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear lista diccionario\n",
    "lista = []\n",
    "for i in range(4):\n",
    "    dicc_valor = dicc_ejemplo.copy()\n",
    "    dicc_valor[\"cantante\"] = f\"Rosalia_{i}\"\n",
    "    lista.append(dicc_valor)\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657408e-d52a-4a90-8f35-05c8b92dad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/ejemplo_lista.json\",\"w\") as g:\n",
    "    json.dump(lista,g)#datos variable lista a g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417d056-6800-4f33-a9fc-cff1d1c72ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/ejemplo_lista.json\",\"r\") as f:\n",
    "    print(json.load(f))#lista recuperrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13072831-c4fb-483e-b172-c805ead2fc03",
   "metadata": {},
   "source": [
    "## ACCESO LOCAL: JSON (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c0d7e-6509-402f-bcf5-5865f716c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/Musical_Instruments_5.json\",\"r\") as f:\n",
    "    datos = [json.loads(linea) for linea in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ea087-6fa9-41b7-a571-886c5a91f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datos) #ver longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083690c-5309-494d-bc1a-a9d0dd69684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprimir datos seleccionados entre:\n",
    "datos[25:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd1d423-fc31-4e3b-adf7-e56315d0b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir a df\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"./data/Musical_Instruments_5.json\", lines = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c78154-8d69-4028-b6dc-f246736698ca",
   "metadata": {},
   "source": [
    "### De json a pandas en más de un paso\n",
    "crear un dataframe con un archivo Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bf19de-4cb9-45d4-b6bd-4fb4b6643101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/presidentes.json\",\"r\") as f:\n",
    "    presidentes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ace4e0-9258-4be8-aa4f-047fced01088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(presidentes)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7bafd2-d1c7-4034-96e6-6537f077082b",
   "metadata": {},
   "source": [
    "Se puede hacer con el archivo  `read_json`, se suelen hacer más con otros datos como csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd93c2-0eff-4e53-9253-84a62304efc3",
   "metadata": {},
   "source": [
    "### Manipulando ficheros json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57138fff-d851-4a35-a495-6287adf347ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./05_Ficheros_json_II.ipynb\",\"r\") as f:\n",
    "    notebook = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55073498-e40d-49f9-83fd-ac95254e06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook#nos da la informacion a lo bruto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137e784-2508-4257-9ca5-dcc1b11ca1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(notebook) #nos da dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae0623-e5de-4ffb-8486-141088daef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook.keys() #claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa6f42-37b2-4aef-a889-2abbe81e3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(notebook[\"cells\"]) #nos dice que es una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79301d6a-44d3-47df-8878-f7beaa0f6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook[\"cells\"][0].keys() #claves del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b1edd-39b3-4d00-8710-7c8956f56a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook[\"cells\"][0][\"cell_type\"] #nos dice el tipo de celda que es markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59d6ff-fe38-4f35-8df0-98e05e46e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorrer lasd celdas del diccionario, para ver cuales tienen  código\n",
    "for celda in notebook[\"cells\"]:\n",
    "    if celda[\"cell_type\"] == \"code\":\n",
    "        print(celda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e53da-07e7-43b8-84f1-9154ab70343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pedir que solo nos printe el contenido de las celdas con código\n",
    "for celda in notebook[\"cells\"]:\n",
    "    if celda[\"cell_type\"] == \"code\":\n",
    "        print(celda[\"source\"]) #source contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad232ee-712b-4ebe-aee9-43046791741b",
   "metadata": {},
   "source": [
    "## ETL: Tratamiento de Textos (I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa76c4-7568-42ab-a7b0-b3748dbca736",
   "metadata": {},
   "source": [
    "El formato **XML** (eXtensible Markup Language) es parecido al HTML, pero es más estructurado\n",
    "se empieza con una declarfación de uno o dos <root>, como en html. Se escribe seguido de nodos.\n",
    "Le siguen subnodos, valores y atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120795e0-0279-4c69-9b6a-198f887bab54",
   "metadata": {},
   "source": [
    "<img src=\"https://www.cdn.geeksforgeeks.org/wp-content/uploads/parsing-XML.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3881b7-2188-4796-bd68-b602f1e33780",
   "metadata": {},
   "source": [
    "company-nodo raiz\n",
    "departamento, que tiene un empleado y a su vez segundo nempleado, frente al otro departamento sin valores.\n",
    "Cada empleado tiene sus atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35773169-b0be-4dd8-b374-9b683c011c55",
   "metadata": {},
   "source": [
    "### Lectura de ficheros XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69929f2e-b39f-481f-9000-959587cbb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/cd_catalog.xml\",\"r\") as f:\n",
    "    for line in f:\n",
    "        print(line, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe764d65-f8df-4f2f-8ab4-daa3f120eabc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 149) (2179843687.py, line 149)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 149\u001b[1;36m\u001b[0m\n\u001b[1;33m    <ARTIST>T'Pau</ARTIST>\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 149)\n"
     ]
    }
   ],
   "source": [
    "#el fichero\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>    #le dice para quien lo lea\n",
    "<CATALOG>           no vuelve a aparecer catalog hasta el final del archivo, al final cierra laetiqueta. es el nodo raiz\n",
    "  <CD id=\"1\">          siguiente nodo, al ir con tabiuladores, se ve cual es el siguiente nodo\n",
    "    <TITLE>Empire Burlesque</TITLE>       estos son los nodos de cd con texto o valor.\n",
    "    <ARTIST>Bob Dylan</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>Columbia</COMPANY>\n",
    "    <PRICE>10.90</PRICE>\n",
    "    <YEAR>1985</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"2\">\n",
    "    <TITLE>Hide your heart</TITLE>\n",
    "    <ARTIST>Bonnie Tyler</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>CBS Records</COMPANY>\n",
    "    <PRICE>9.90</PRICE>\n",
    "    <YEAR>1988</YEAR>\"\n",
    "  </CD>\n",
    "  <CD id=\"3\">\n",
    "    <TITLE>Greatest Hits</TITLE>\n",
    "    <ARTIST>Dolly Parton</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>RCA</COMPANY>\n",
    "    <PRICE>9.90</PRICE>\n",
    "    <YEAR>1982</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"4\">\n",
    "    <TITLE>Still got the blues</TITLE>\n",
    "    <ARTIST>Gary Moore</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Virgin records</COMPANY>\n",
    "    <PRICE>10.20</PRICE>\n",
    "    <YEAR>1990</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"5\">\n",
    "    <TITLE>Eros</TITLE>\n",
    "    <ARTIST>Eros Ramazzotti</ARTIST>\n",
    "    <COUNTRY>EU</COUNTRY>\n",
    "    <COMPANY>BMG</COMPANY>\n",
    "    <PRICE>9.90</PRICE>\n",
    "    <YEAR>1997</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"6\">\n",
    "    <TITLE>One night only</TITLE>\n",
    "    <ARTIST>Bee Gees</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Polydor</COMPANY>\n",
    "    <PRICE>10.90</PRICE>\n",
    "    <YEAR>1998</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"7\">\n",
    "    <TITLE>Sylvias Mother</TITLE>\n",
    "    <ARTIST>Dr.Hook</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>CBS</COMPANY>\n",
    "    <PRICE>8.10</PRICE>\n",
    "    <YEAR>1973</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"8\">\n",
    "    <TITLE>Maggie May</TITLE>\n",
    "    <ARTIST>Rod Stewart</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Pickwick</COMPANY>\n",
    "    <PRICE>8.50</PRICE>\n",
    "    <YEAR>1990</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"9\">\n",
    "    <TITLE>Romanza</TITLE>\n",
    "    <ARTIST>Andrea Bocelli</ARTIST>\n",
    "    <COUNTRY>EU</COUNTRY>\n",
    "    <COMPANY>Polydor</COMPANY>\n",
    "    <PRICE>10.80</PRICE>\n",
    "    <YEAR>1996</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"10\">\n",
    "    <TITLE>When a man loves a woman</TITLE>\n",
    "    <ARTIST>Percy Sledge</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>Atlantic</COMPANY>\n",
    "    <PRICE>8.70</PRICE>\n",
    "    <YEAR>1987</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"11\">\n",
    "    <TITLE>Black angel</TITLE>\n",
    "    <ARTIST>Savage Rose</ARTIST>\n",
    "    <COUNTRY>EU</COUNTRY>\n",
    "    <COMPANY>Mega</COMPANY>\n",
    "    <PRICE>10.90</PRICE>\n",
    "    <YEAR>1995</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"12\">\n",
    "    <TITLE>1999 Grammy Nominees</TITLE>\n",
    "    <ARTIST>Many</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>Grammy</COMPANY>\n",
    "    <PRICE>10.20</PRICE>\n",
    "    <YEAR>1999</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"13\">\n",
    "    <TITLE>For the good times</TITLE>\n",
    "    <ARTIST>Kenny Rogers</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Mucik Master</COMPANY>\n",
    "    <PRICE>8.70</PRICE>\n",
    "    <YEAR>1995</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"14\">\n",
    "    <TITLE>Big Willie style</TITLE>\n",
    "    <ARTIST>Will Smith</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>Columbia</COMPANY>\n",
    "    <PRICE>9.90</PRICE>\n",
    "    <YEAR>1997</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"15\">\n",
    "    <TITLE>Tupelo Honey</TITLE>\n",
    "    <ARTIST>Van Morrison</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Polydor</COMPANY>\n",
    "    <PRICE>8.20</PRICE>\n",
    "    <YEAR>1971</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"16\">\n",
    "    <TITLE>Soulsville</TITLE>\n",
    "    <ARTIST>Jorn Hoel</ARTIST>\n",
    "    <COUNTRY>Norway</COUNTRY>\n",
    "    <COMPANY>WEA</COMPANY>\n",
    "    <PRICE>7.90</PRICE>\n",
    "    <YEAR>1996</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"17\">\n",
    "    <TITLE>The very best of</TITLE>\n",
    "    <ARTIST>Cat Stevens</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Island</COMPANY>\n",
    "    <PRICE>8.90</PRICE>\n",
    "    <YEAR>1990</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"18\">\n",
    "    <TITLE>Stop</TITLE>\n",
    "    <ARTIST>Sam Brown</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>A and M</COMPANY>\n",
    "    <PRICE>8.90</PRICE>\n",
    "    <YEAR>1988</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"19\">\n",
    "    <TITLE>Bridge of Spies</TITLE>\n",
    "    <ARTIST>T'Pau</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Siren</COMPANY>\n",
    "    <PRICE>7.90</PRICE>\n",
    "    <YEAR>1987</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"20\">\n",
    "    <TITLE>Private Dancer</TITLE>\n",
    "    <ARTIST>Tina Turner</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>Capitol</COMPANY>\n",
    "    <PRICE>8.90</PRICE>\n",
    "    <YEAR>1983</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"21\">\n",
    "    <TITLE>Midt om natten</TITLE>\n",
    "    <ARTIST>Kim Larsen</ARTIST>\n",
    "    <COUNTRY>EU</COUNTRY>\n",
    "    <COMPANY>Medley</COMPANY>\n",
    "    <PRICE>7.80</PRICE>\n",
    "    <YEAR>1983</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"22\">\n",
    "    <TITLE>Pavarotti Gala Concert</TITLE>\n",
    "    <ARTIST>Luciano Pavarotti</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>DECCA</COMPANY>\n",
    "    <PRICE>9.90</PRICE>\n",
    "    <YEAR>1991</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"23\">\n",
    "    <TITLE>The dock of the bay</TITLE>\n",
    "    <ARTIST>Otis Redding</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>Stax Records</COMPANY>\n",
    "    <PRICE>7.90</PRICE>\n",
    "    <YEAR>1968</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"24\">\n",
    "    <TITLE>Picture book</TITLE>\n",
    "    <ARTIST>Simply Red</ARTIST>\n",
    "    <COUNTRY>EU</COUNTRY>\n",
    "    <COMPANY>Elektra</COMPANY>\n",
    "    <PRICE>7.20</PRICE>\n",
    "    <YEAR>1985</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"25\">\n",
    "    <TITLE>Red</TITLE>\n",
    "    <ARTIST>The Communards</ARTIST>\n",
    "    <COUNTRY>UK</COUNTRY>\n",
    "    <COMPANY>London</COMPANY>\n",
    "    <PRICE>7.80</PRICE>\n",
    "    <YEAR>1987</YEAR>\n",
    "  </CD>\n",
    "  <CD id=\"99\">\n",
    "    <TITLE>Unchain my heart</TITLE>\n",
    "    <ARTIST>Joe Cocker</ARTIST>\n",
    "    <COUNTRY>USA</COUNTRY>\n",
    "    <COMPANY>EMI</COMPANY>\n",
    "    <PRICE>8.20</PRICE>\n",
    "    <YEAR>1987</YEAR>\n",
    "  </CD>\n",
    "</CATALOG>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d51a10-554c-4002-9250-0fe33c6adde0",
   "metadata": {},
   "source": [
    "para poder procesar un fichero xml Lo vamos a hacer con ayuda de la librería `ElementTree`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a232837-f18b-4432-8ed5-e2f93ccd705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2cbd85-fe9c-4fcc-bbb0-908719701751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsear el fichero, parsear es extraer datos leyendo de una estructura determinada\n",
    "tree = ET.parse(\"./data/cd_catalog.xml\")\n",
    "#el tree tiene nuevos atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e5d3d-2c8e-4c44-a68d-747068e1519e",
   "metadata": {},
   "source": [
    "Esta librería trata el XML como si fuese un árbol. En este formato de árbol, disponemos de diversos métodos con los que podemos extraer partes del XML. \n",
    "\n",
    "* `tag` muestra el texto dentro de la etiqueta\n",
    "* `attrib` muestra los atributos de la etiqueta\n",
    "* `text` muestra el texto del nodo\n",
    "* La función `iter()` permite conocer la estructura del XML\n",
    "* La función `find()` busca en el XML y devuelve el elemento que coincide con la etiqueta especificada.  \n",
    "* La función `findall()` devuelve todos los elementos con cierta etiquetatiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cb263-a81f-4875-bab1-f23fb4a631af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la etiqueta del nodo raiz:\n",
    "raiz = tree.getroot()\n",
    "#veremos el tag, el tag es <xxxx>\n",
    "raiz.tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b9156-3243-4da4-abbc-6d33d335160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada elemento sus etiqueta\n",
    "#podemos recorrerlo\n",
    "for elemento in raiz.iter():\n",
    "    print(elemento.tag)\n",
    "    #nos pone todos los tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df974d-2d43-4341-bbf3-821f4b460f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorrido con cierta jerarquia\n",
    "for hijo in raiz:\n",
    "    tabs = \"\\t\"\n",
    "    print(hijo.tag,hijo.attrib)\n",
    "    #nos da los cd y el id a modo de diccionario\n",
    "    for nieto in hijo:\n",
    "        print(tabs,nieto.tag,nieto.text)#sabemos que tiene texto aunque nno ntenga atribuito y nos lo da ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da078071-f078-4f5a-9088-b8e1bc7bd2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscar elementos de cada uno nde los posibles nodos\n",
    "cds = tree.findall(\"CD\")\n",
    "for cd in cds:\n",
    "    print(\"id:\", cd.attrib[\"id\"])\n",
    "    print(\"Titulo:\",cd.find(\"TITLE\").text )\n",
    "    print(\"Titulo:\",cd.find(\"ARTIST\").text )#estos valores iguales no se repiten, por lo que hay que mirar un poco el xml\n",
    "    #igual las etiquetas no están definidas como en al html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0aaed9-a16f-4ea7-806b-e49c70773b8e",
   "metadata": {},
   "source": [
    "desde las dos formas podemos coger datos y crear el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612c2d3-b179-4538-ae8d-3fcbedb9aff6",
   "metadata": {},
   "source": [
    "## ACCESO LOCAL: XML (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecfdb75-0101-4c0a-a34c-5bd857319c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e80a38-cc1c-46f5-8a55-503efbb2c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./data/movies.xml\", \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line, end = \"\") #podemos calcular el npodo raiz, navegar por el fichero poara sacar la info necesareia \n",
    "                              # para construir un diccionario y con el el df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098ccd7-f0af-447c-8855-7a8f0e8a5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_movies = ET.parse(\"./data/movies.xml\")\n",
    "raiz = tree_movies.getroot()\n",
    "print(raiz.tag) #el print da movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3590b-f60b-4460-91df-16003d2937cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorrer raiz\n",
    "for hijo in raiz:\n",
    "    tabs = \"\\t\"\n",
    "    level = 0\n",
    "    print(hijo.tag)#para ver el tag inicial\n",
    "    for nieto in hijo:\n",
    "        level = 1\n",
    "        print(tabs*level, nieto.tag,nieto.txt) #me printa tantos tag como leveles\n",
    "        for bisnieto in nieto: #para cada tag por `película pedimos que nos printe el valor y lña etiqueta\n",
    "            level = 2 #no sabemos cuantos niveles hay\n",
    "            print(tabs*level, bisnieto.tag, bisnieto.text)#en el caso de que se alargase, es mejor hacer una función para b uscarlo\n",
    "            for tataranieto in bisnieto:\n",
    "                level = 3\n",
    "                 print(tabs*level, tataranieto.tag,tataranieto.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b14a91-f2a5-4ed8-9092-ebfc7baa3522",
   "metadata": {},
   "source": [
    "movie\n",
    "\t title A History of Violence\n",
    "\t year 2005\n",
    "\t country USA\n",
    "\t genre Crime\n",
    "\t summary Tom Stall, a humble family man and owner of a \n",
    "\tpopular neighborhood restaurant, lives a quiet but \n",
    "\tfulfilling existence in the Midwest. One night Tom \n",
    "\tfoils a crime at his place of business and, to his \n",
    "\tchagrin, is plastered all over the news for his \n",
    "\theroics. Following this, mysterious people follow \n",
    "\tthe Stalls' every move, concerning Tom more than \n",
    "\tanyone else. As this situation is confronted, more \n",
    "\tlurks out over where all these occurrences have \n",
    "\tstemmed from compromising his marriage, family \n",
    "\trelationship and the main characters' former \n",
    "\trelations in the process.\n",
    "\t director \t    \n",
    "\t\t last_name Cronenberg\n",
    "\t\t first_name David\n",
    "\t\t birth_date 1943\n",
    "\t actor \n",
    "\t    \n",
    "\t\t first_name Vigo\n",
    "\t\t last_name Mortensen\n",
    "...\n",
    "\t\t first_name Willem\n",
    "\t\t last_name Dafoe\n",
    "\t\t birth_date 1955\n",
    "\t\t role Green Goblin / Norman Osborn\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d125ff-3dbe-4393-91ac-9df80c79449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nos da esta información para saber como queremos hacer el análisis, cogemos título, película, director..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b8477-8f14-4e7b-b3fb-663d249618f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacemos un diccionario de listas, para esta información\n",
    "dict_df = {\n",
    "    \"title\": [],\n",
    "    \"year\": [],\n",
    "    \"country\":[],\n",
    "    \"genre\": [],\n",
    "    \"summary\": [],\n",
    "    \"director\": [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa731ef-b55b-4abc-9d4f-ba7db95a7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hijo in raiz:\n",
    "    tabs = \"\\t\"\n",
    "    level = 0\n",
    "    print(hijo.tag)\n",
    "    campos_a_rellenar = list(dict_df.keys()) #agregamos esto para rellenar el dicionario\n",
    "    for nieto in hijo:\n",
    "        level = 1\n",
    "        print(tabs*level, nieto.tag,nieto.text) \n",
    "        if nieto.tag in dict_df and nieto.tag != \"director\": #director es diferente porque requiere otro procesamiento\n",
    "            dict_df[nieto.tag].append(nieto.text)#columna(keys) y valor(nieto.tag)\n",
    "            campos_a_rellenar.remove(nieto.tag) #a medidas que relleno campos, lo quitamos de la lista de campos\n",
    "            #cuando acabamos con los datos de una peli (hijo), compruebo que campos nos faltan por rellenar y se rellena con un campo especial\n",
    "        elif nieto.tag == \"director\": #nos metemos dentro de la etiqueta de director\n",
    "            for bisnieto in nieto: \n",
    "                level = 2\n",
    "                print(tabs*level, bisnieto.tag, bisnieto.text)\n",
    "                if bisnieto.tag ==\"first_name\":\n",
    "                    nombre = bisnieto.text\n",
    "                elif bisnieto.tag == \"last_name\":\n",
    "                    apellido = bisnieto.text\n",
    "            nombre_completo = f\"{nombre} {apellido}\"\n",
    "            dict_df[\"director\"].append(nombre_completo) #añado al campo director con un append\n",
    "            campos_a_rellenar.remove(\"director\")#valor especial\n",
    "    for campo in campos_a_rellenar:\n",
    "        dict_df[campo].append(\"No tengo datos\")#cuando termino de procesar datos de al película comprobamos for campos in campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3359ee7-a559-47b2-b9ca-ace1ec329b35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdict_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_df' is not defined"
     ]
    }
   ],
   "source": [
    "dict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b7dd1b-7165-445a-a6dd-8167dd46c830",
   "metadata": {},
   "source": [
    "{'title': ['A History of Violence',\n",
    "  'Heat',\n",
    "  'Unforgiven',\n",
    "  'Match Point',\n",
    "  'Lost in Translation',\n",
    "  'Marie Antoinette',\n",
    "  'Spider-Man',\n",
    "  'A History of Violence',\n",
    "  'Heat',\n",
    "  'Unforgiven',\n",
    "  'Match Point',\n",
    "  'Lost in Translation',\n",
    "  'A History of Violence',\n",
    "  'Heat',\n",
    "  'Unforgiven',\n",
    "  'Match Point',\n",
    "  'Lost in Translation',\n",
    "  'A History of Violence',\n",
    "  'Heat',\n",
    "  'Unforgiven',\n",
    "  'Match Point',\n",
    "  'Lost in Translation',\n",
    "  'Marie Antoinette',\n",
    "  'Spider-Man'],\n",
    " 'year': ['2005',\n",
    "...\n",
    "  'Clint Eastwood',\n",
    "  'Woody Allen',\n",
    "  'Sofia Coppola',\n",
    "  'Sofia Coppola',\n",
    "  'Sam Raimi']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211c1dd-9f39-4daf-868f-122185e58c58",
   "metadata": {},
   "source": [
    "nos da el diccionario y creamos un dataframe con ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19029e07-485c-4acf-8a8d-c914911dccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hijo in raiz:\n",
    "    tabs = \"\\t\"\n",
    "    level = 0\n",
    "    print(hijo.tag)\n",
    "    campos_a_rellenar = list(dict_df.keys())  # Lista de campos a rellenar en el diccionario\n",
    "    \n",
    "        for nieto in hijo:\n",
    "            level = 1\n",
    "            print(tabs * level, nieto.tag, nieto.text) \n",
    "            \n",
    "            # Comprobación de existencia de la etiqueta y relleno del diccionario\n",
    "            if nieto.tag in dict_df and nieto.tag != \"director\":\n",
    "                dict_df[nieto.tag].append(nieto.text)\n",
    "                campos_a_rellenar.remove(nieto.tag)  # Remover campo ya rellenado\n",
    "            \n",
    "            # Procesamiento de etiqueta 'director'\n",
    "            elif nieto.tag == \"director\":\n",
    "                for bisnieto in nieto: \n",
    "                    level = 2\n",
    "                    print(tabs * level, bisnieto.tag, bisnieto.text)\n",
    "                    if bisnieto.tag == \"first_name\":\n",
    "                        nombre = bisnieto.text\n",
    "                    elif bisnieto.tag == \"last_name\":\n",
    "                        apellido = bisnieto.text\n",
    "                nombre_completo = f\"{nombre} {apellido}\"\n",
    "                dict_df[\"director\"].append(nombre_completo)\n",
    "                campos_a_rellenar.remove(\"director\")\n",
    "        \n",
    "        # Relleno con \"No tengo datos\" para los campos no llenados\n",
    "        for campo in campos_a_rellenar:\n",
    "            dict_df[campo].append(\"No tengo datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12a5f92-19b9-44cb-b320-68b2e25a6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_xml(\"/data/movie.xml\") #no me va tampoco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
